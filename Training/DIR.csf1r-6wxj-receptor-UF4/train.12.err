Error.  nthreads cannot be larger than environment variable "NUMEXPR_MAX_THREADS" (64)/lus/gila/projects/candle_aesp_CNDA/avasan/envs/sst_2024/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).
  from pandas.core.computation.check import NUMEXPR_INSTALLED
2024-07-12 14:38:57.509486: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-07-12 14:38:57.560879: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2024-07-12 14:38:57.593583: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-07-12 14:38:57.593602: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-07-12 14:38:57.594882: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-07-12 14:38:57.601681: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2024-07-12 14:38:57.601876: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-07-12 14:38:59.896563: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-07-12 14:39:02.733262: W external/local_tsl/tsl/lib/monitoring/collection_registry.cc:81] Trying to register 2 metrics with the same name: /tensorflow/core/bfc_allocator_delay. The old value will be erased in order to register a new one. Please check if you link the metric more than once, or if the name is already used by other metrics.
2024-07-12 14:39:02.733500: W external/local_tsl/tsl/lib/monitoring/collection_registry.cc:81] Trying to register 2 metrics with the same name: /xla/service/gpu/compiled_programs_count. The old value will be erased in order to register a new one. Please check if you link the metric more than once, or if the name is already used by other metrics.
2024-07-12 14:39:02.734831: W external/local_tsl/tsl/lib/monitoring/collection_registry.cc:81] Trying to register 2 metrics with the same name: /jax/pjrt/pjrt_executable_executions. The old value will be erased in order to register a new one. Please check if you link the metric more than once, or if the name is already used by other metrics.
2024-07-12 14:39:02.734839: W external/local_tsl/tsl/lib/monitoring/collection_registry.cc:81] Trying to register 2 metrics with the same name: /jax/pjrt/pjrt_executable_execution_time_usecs. The old value will be erased in order to register a new one. Please check if you link the metric more than once, or if the name is already used by other metrics.
2024-07-12 14:39:02.983647: I itex/core/wrapper/itex_gpu_wrapper.cc:38] Intel Extension for Tensorflow* GPU backend is loaded.
2024-07-12 14:39:02.985912: I external/local_xla/xla/pjrt/pjrt_api.cc:67] PJRT_Api is set for device type xpu
2024-07-12 14:39:02.985928: I external/local_xla/xla/pjrt/pjrt_api.cc:72] PJRT plugin for XPU has PJRT API version 0.33. The framework PJRT API version is 0.34.
2024-07-12 14:39:03.007058: I external/intel_xla/xla/stream_executor/sycl/sycl_gpu_runtime.cc:134] Selected platform: Intel(R) Level-Zero
2024-07-12 14:39:03.022590: I external/xla/xla/service/service.cc:168] XLA service 0x559559efe230 initialized for platform SYCL (this does not guarantee that XLA will be used). Devices:
2024-07-12 14:39:03.022650: I external/xla/xla/service/service.cc:176]   StreamExecutor device (0): Intel(R) Data Center GPU Max 1550, <undefined>
2024-07-12 14:39:03.022654: I external/xla/xla/service/service.cc:176]   StreamExecutor device (1): Intel(R) Data Center GPU Max 1550, <undefined>
2024-07-12 14:39:03.022656: I external/xla/xla/service/service.cc:176]   StreamExecutor device (2): Intel(R) Data Center GPU Max 1550, <undefined>
2024-07-12 14:39:03.022659: I external/xla/xla/service/service.cc:176]   StreamExecutor device (3): Intel(R) Data Center GPU Max 1550, <undefined>
2024-07-12 14:39:03.022661: I external/xla/xla/service/service.cc:176]   StreamExecutor device (4): Intel(R) Data Center GPU Max 1550, <undefined>
2024-07-12 14:39:03.022663: I external/xla/xla/service/service.cc:176]   StreamExecutor device (5): Intel(R) Data Center GPU Max 1550, <undefined>
2024-07-12 14:39:03.022665: I external/xla/xla/service/service.cc:176]   StreamExecutor device (6): Intel(R) Data Center GPU Max 1550, <undefined>
2024-07-12 14:39:03.022667: I external/xla/xla/service/service.cc:176]   StreamExecutor device (7): Intel(R) Data Center GPU Max 1550, <undefined>
2024-07-12 14:39:03.022669: I external/xla/xla/service/service.cc:176]   StreamExecutor device (8): Intel(R) Data Center GPU Max 1550, <undefined>
2024-07-12 14:39:03.022671: I external/xla/xla/service/service.cc:176]   StreamExecutor device (9): Intel(R) Data Center GPU Max 1550, <undefined>
2024-07-12 14:39:03.022672: I external/xla/xla/service/service.cc:176]   StreamExecutor device (10): Intel(R) Data Center GPU Max 1550, <undefined>
2024-07-12 14:39:03.022674: I external/xla/xla/service/service.cc:176]   StreamExecutor device (11): Intel(R) Data Center GPU Max 1550, <undefined>
2024-07-12 14:39:03.023090: I itex/core/devices/gpu/itex_gpu_runtime.cc:130] Selected platform: Intel(R) Level-Zero
2024-07-12 14:39:03.037504: I external/intel_xla/xla/pjrt/se_xpu_pjrt_client.cc:97] Using BFC allocator.
2024-07-12 14:39:03.037529: I external/xla/xla/pjrt/gpu/gpu_helpers.cc:106] XLA backend allocating 61847529062 bytes on device 0 for BFCAllocator.
2024-07-12 14:39:03.037558: I external/xla/xla/pjrt/gpu/gpu_helpers.cc:106] XLA backend allocating 61847529062 bytes on device 1 for BFCAllocator.
2024-07-12 14:39:03.037563: I external/xla/xla/pjrt/gpu/gpu_helpers.cc:106] XLA backend allocating 61847529062 bytes on device 2 for BFCAllocator.
2024-07-12 14:39:03.037568: I external/xla/xla/pjrt/gpu/gpu_helpers.cc:106] XLA backend allocating 61847529062 bytes on device 3 for BFCAllocator.
2024-07-12 14:39:03.037572: I external/xla/xla/pjrt/gpu/gpu_helpers.cc:106] XLA backend allocating 61847529062 bytes on device 4 for BFCAllocator.
2024-07-12 14:39:03.037576: I external/xla/xla/pjrt/gpu/gpu_helpers.cc:106] XLA backend allocating 61847529062 bytes on device 5 for BFCAllocator.
2024-07-12 14:39:03.037579: I external/xla/xla/pjrt/gpu/gpu_helpers.cc:106] XLA backend allocating 61847529062 bytes on device 6 for BFCAllocator.
2024-07-12 14:39:03.037584: I external/xla/xla/pjrt/gpu/gpu_helpers.cc:106] XLA backend allocating 61847529062 bytes on device 7 for BFCAllocator.
2024-07-12 14:39:03.037589: I external/xla/xla/pjrt/gpu/gpu_helpers.cc:106] XLA backend allocating 61847529062 bytes on device 8 for BFCAllocator.
2024-07-12 14:39:03.037592: I external/xla/xla/pjrt/gpu/gpu_helpers.cc:106] XLA backend allocating 61847529062 bytes on device 9 for BFCAllocator.
2024-07-12 14:39:03.037596: I external/xla/xla/pjrt/gpu/gpu_helpers.cc:106] XLA backend allocating 61847529062 bytes on device 10 for BFCAllocator.
2024-07-12 14:39:03.037598: I external/xla/xla/pjrt/gpu/gpu_helpers.cc:106] XLA backend allocating 61847529062 bytes on device 11 for BFCAllocator.
2024-07-12 14:39:03.049190: I external/local_xla/xla/pjrt/pjrt_c_api_client.cc:119] PjRtCApiClient created.
2024-07-12 14:41:11.918865: I tensorflow/core/common_runtime/next_pluggable_device/next_pluggable_device_factory.cc:118] Created 12 TensorFlow NextPluggableDevices. Physical device type: XPU
WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.
2024-07-12 14:41:15.037437: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type XPU is enabled.
Traceback (most recent call last):
  File "/lus/gila/projects/candle_aesp_CNDA/avasan/Workflows/Uchic_Aur_Screens/Training/DIR.csf1r-6wxj-receptor-UF4/../surrogate_training/train_model.py", line 64, in <module>
    history = train_and_callbacks.training(
  File "/lus/gila/projects/candle_aesp_CNDA/avasan/Workflows/Uchic_Aur_Screens/Training/surrogate_training/ST_funcs/smiles_regress_transformer_funcs.py", line 415, in training
    history = model.fit(
  File "/lus/gila/projects/candle_aesp_CNDA/avasan/envs/sst_2024/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py", line 65, in error_handler
    return fn(*args, **kwargs)
  File "/lus/gila/projects/candle_aesp_CNDA/avasan/envs/sst_2024/lib/python3.9/site-packages/keras/src/engine/training.py", line 1807, in fit
    tmp_logs = self.train_function(iterator)
  File "/lus/gila/projects/candle_aesp_CNDA/avasan/envs/sst_2024/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py", line 150, in error_handler
    return fn(*args, **kwargs)
  File "/lus/gila/projects/candle_aesp_CNDA/avasan/envs/sst_2024/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py", line 832, in __call__
    result = self._call(*args, **kwds)
  File "/lus/gila/projects/candle_aesp_CNDA/avasan/envs/sst_2024/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py", line 868, in _call
    return tracing_compilation.call_function(
  File "/lus/gila/projects/candle_aesp_CNDA/avasan/envs/sst_2024/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py", line 139, in call_function
    return function._call_flat(  # pylint: disable=protected-access
  File "/lus/gila/projects/candle_aesp_CNDA/avasan/envs/sst_2024/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py", line 1323, in _call_flat
    return self._inference_function.call_preflattened(args)
  File "/lus/gila/projects/candle_aesp_CNDA/avasan/envs/sst_2024/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py", line 216, in call_preflattened
    flat_outputs = self.call_flat(*args)
  File "/lus/gila/projects/candle_aesp_CNDA/avasan/envs/sst_2024/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py", line 251, in call_flat
    outputs = self._bound_context.call_function(
  File "/lus/gila/projects/candle_aesp_CNDA/avasan/envs/sst_2024/lib/python3.9/site-packages/tensorflow/python/eager/context.py", line 1486, in call_function
    outputs = execute.execute(
  File "/lus/gila/projects/candle_aesp_CNDA/avasan/envs/sst_2024/lib/python3.9/site-packages/tensorflow/python/eager/execute.py", line 53, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
KeyboardInterrupt
